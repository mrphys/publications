{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918a9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing author: Silvia Schievano\n",
      "Processing author: Claudio Capelli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214076/192034869.py:146: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[df['Affiliations'].astype(str).str.contains(affil_pattern, na=False)].dropna()\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 148\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Filter\u001b[39;00m\n\u001b[1;32m    146\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAffiliations\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(affil_pattern, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m--> 148\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/pubs_silvia.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/core/generic.py:2702\u001b[0m, in \u001b[0;36mNDFrame.to_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m   2699\u001b[0m config\u001b[38;5;241m.\u001b[39mis_nonnegative_int(indent)\n\u001b[1;32m   2700\u001b[0m indent \u001b[38;5;241m=\u001b[39m indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2705\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/io/json/_json.py:217\u001b[0m, in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m     s \u001b[38;5;241m=\u001b[39m convert_to_line_delimits(s)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_or_buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    220\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mwrite(s)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "def fetch_pubmed_ids(author, retmax=200):\n",
    "    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': f'{author}[Author]',\n",
    "        'retmax': retmax,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    root = ET.fromstring(response.content)\n",
    "    ids = [id_elem.text for id_elem in root.findall('./IdList/Id')]\n",
    "    return ids\n",
    "\n",
    "def fetch_pubmed_records(id_list):\n",
    "    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "    if not id_list:\n",
    "        return b''  # return empty bytes if no IDs\n",
    "    ids = ','.join(id_list)\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': ids,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.content\n",
    "\n",
    "def parse_pubmed_xml(xml_data):\n",
    "    if not xml_data:\n",
    "        return []\n",
    "    root = ET.fromstring(xml_data)\n",
    "    records = []\n",
    "    for article in root.findall('.//PubmedArticle'):\n",
    "        try:\n",
    "            article_title = article.findtext('.//ArticleTitle')\n",
    "            journal = article.findtext('.//Journal/Title')\n",
    "\n",
    "            if len(article_title) < 4:\n",
    "                article_title = pd.NA  # you used np.nan, but pandas NA is cleaner in newer versions\n",
    "\n",
    "            authors = []\n",
    "            affiliations = set()\n",
    "\n",
    "            for author in article.findall('.//AuthorList/Author'):\n",
    "                last = author.findtext('LastName')\n",
    "                fore = author.findtext('ForeName')\n",
    "                if last and fore:\n",
    "                    authors.append(f\"{last} {fore[0]}.\")\n",
    "                elif last:\n",
    "                    authors.append(last)\n",
    "\n",
    "                # Affiliation (can be multiple)\n",
    "                aff_list = author.findall('.//AffiliationInfo/Affiliation')\n",
    "                for aff in aff_list:\n",
    "                    if aff is not None and aff.text:\n",
    "                        affiliations.add(aff.text.strip())\n",
    "\n",
    "            authors = ', '.join(authors)\n",
    "            affiliation_str = '; '.join(affiliations) if affiliations else None\n",
    "\n",
    "            pub_date_elem = article.find('.//Journal/JournalIssue/PubDate')\n",
    "            pub_date_str = None\n",
    "            year = None\n",
    "            if pub_date_elem is not None:\n",
    "                year = pub_date_elem.findtext('Year')\n",
    "                medline_date = pub_date_elem.findtext('MedlineDate')\n",
    "                month = pub_date_elem.findtext('Month')\n",
    "                day = pub_date_elem.findtext('Day')\n",
    "                if year:\n",
    "                    pub_date_str = year\n",
    "                    if month:\n",
    "                        pub_date_str += f\"-{month}\"\n",
    "                    if day:\n",
    "                        pub_date_str += f\"-{day}\"\n",
    "                elif medline_date:\n",
    "                    pub_date_str = medline_date\n",
    "\n",
    "            doi = None\n",
    "            for article_id in article.findall('.//ArticleIdList/ArticleId'):\n",
    "                if article_id.attrib.get('IdType') == 'doi':\n",
    "                    doi = article_id.text\n",
    "                    break\n",
    "\n",
    "            records.append({\n",
    "                'Title': article_title,\n",
    "                'Journal': journal,\n",
    "                'Authors': authors,\n",
    "                'Affiliations': affiliation_str,\n",
    "                'Year': year,\n",
    "                'DOI': doi,\n",
    "                'DocumentType': 'Article',\n",
    "                'PublicationDate': pub_date_str\n",
    "            })\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Convert PublicationDate strings to pandas datetime, coercing errors\n",
    "    for r in records:\n",
    "        date_str = r['PublicationDate']\n",
    "        if date_str:\n",
    "            r['PublicationDate'] = pd.to_datetime(date_str, errors='coerce')\n",
    "        else:\n",
    "            r['PublicationDate'] = pd.NaT\n",
    "    return records\n",
    "\n",
    "\n",
    "\n",
    "# List of authors to process\n",
    "authors_list = [\n",
    "    \"Silvia Schievano\",\n",
    "    \"Claudio Capelli\",\n",
    "]\n",
    "\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for author in authors_list:\n",
    "    print(f\"Processing author: {author}\")\n",
    "    ids = fetch_pubmed_ids(author, retmax=200)\n",
    "    xml_data = fetch_pubmed_records(ids)\n",
    "    records = parse_pubmed_xml(xml_data)\n",
    "    all_records.extend(records)\n",
    "    time.sleep(0.5)  # polite pause to avoid hitting API limits\n",
    "\n",
    "# Convert all records to a DataFrame\n",
    "\n",
    "df = pd.DataFrame(all_records).drop_duplicates('Title').sort_values('PublicationDate', ascending=False)\n",
    "\n",
    "# Build a regex that matches whole phrases (case-insensitive), not substrings\n",
    "affiliations = [\n",
    "    \"UCL\",\n",
    "    \"University College London\",\n",
    "    \"Great Ormond Street\",\n",
    "    \"Royal Free\"\n",
    "]\n",
    "\n",
    "# Create pattern using lookarounds to enforce matching whole phrases\n",
    "affil_pattern = r'(?i)(?<!\\w)(' + '|'.join(re.escape(a) for a in affiliations) + r')(?!\\w)'\n",
    "\n",
    "# Filter\n",
    "df = df[df['Affiliations'].astype(str).str.contains(affil_pattern, na=False)].dropna()\n",
    "\n",
    "df.to_json('data/pubs_silvia.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
